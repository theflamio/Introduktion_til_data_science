---
title: "Data Science Exam: Part 1"
author: "Flemming Christensen"
date: "2024-09-21"
format:
  html:
    toc: true  # Enable the table of contents
    toc_depth: 2  # Specify the depth of headers to include in the TOC
---


```{r}
library(readr)
library(rvest)
library(dplyr)
```


# Introduction
This exam is constructed with 24 Exercises that need to be solved and argumented.
Why this solution or method has been used.

# Exercise 1
Read in the data in the file world_population.csv and select/deselect and rename 
columns so you end up with a tibble (tbl) named wpop_full with 266 rows and 65 
columns with names as shown in the output below (the last column being 2022). 
Hint: Use skip in read_csv to avoid header lines not containing data or names of data.

## import data from csv

```{r}
here::here()

data_dir <- here::here("world_population.csv") #set the directory to were the project and dataset is used

wpop_raw_dat = read_csv(data_dir, skip = 3) # Read csv file and skip the last update info and empty rows

# lets take a look of the data
glimpse(wpop_raw_dat) #looks like there is a lot of NA's in 2023 and the data dose not have column names

```

## Add column names and renaming

```{r}
colnames(wpop_raw_dat) <- as.character(unlist(wpop_raw_dat[1,])) # Make the first row the column names

# next two steps are need to remove exstra column added when making column names

wpop_raw_dat <- wpop_raw_dat[-1, ] # Remove the first row

rownames(wpop_raw_dat) <- NULL # Reset row names

head(wpop_raw_dat) # Confirm that data set now have column names

wpop_raw_dat <- wpop_raw_dat |> # Rename of duplicated meaning in column names
  rename(
    country = `Country Name`,
    code = `Country Code`
  )

head(wpop_raw_dat) # see data structure
```
## Remove unwanted columns
```{r}
wpop_raw_dat <- wpop_raw_dat |> # remove column "indicator Name" and "Indicator Code".
  select(-`Indicator Name`, -`Indicator Code`)

head(wpop_raw_dat) # confirm that columns have been removed.

wpop_full <- wpop_raw_dat |> # Remove year 2023 so that 2022 is last column
  select(-`2023`)
```
## wpop_full result
```{r}
wpop_full
```


# Exercise 2
Use the package rvest to read in the list of country codes from the main table 
at https://en.wikipedia.org/wiki/ISO_3166-1 and select/deselect and rename 
columns so you end up with a tibble (tbl) named iso_codes_all with 249 rows and 
3 columns with names as shown in the output below.

## Web scraping data from Wikipedia
```{r}
url <- "https://en.wikipedia.org/wiki/ISO_3166-1"

webpage <- read_html(url)

tables <- webpage |> 
  html_nodes("table") |>  # Specify the CSS selector for the table. "html_nodes" takes all tables. "html_node" takes only the first.
  html_table()            # Convert the HTML table to a data frame

head(tables) # we need table number 2
  
raw_dat <- tables[[2]] # number 2 table aka ISO 3166-1 table
  

head(raw_dat) # OBS Afghanistan[c] the [C] means that the country is under that category "Naming and disputes" which is correct

```

## remove and rename columns

```{r}
colnames(raw_dat)

raw_dat <- raw_dat |>
  rename(
    name = `English short name  (using title case)`,
    iso3 = `Alpha-3 code`,
    independent = `Independent[b]`
  )

colnames(raw_dat) #check rename was done

iso_codes_all <- raw_dat |>
  select(name, iso3, independent)

```
## iso_codes_all result
```{r}
iso_codes_all
```

# Exercise 3
Use filter() to extract the independent countries from iso_codes_all and save the result as iso_codes.

```{r}
iso_codes <- iso_codes_all |>
  filter(independent == "Yes")

iso_codes
```


# Exercise 4
Use a suitable join (and/or filter) command to make a dataset wpop only containing those rows of wpop_full which have a matching ISO country code in iso_codes:

```{r}
# return only rows that have a match in the iso_codes without columns therefore semi_join and not inner_join
wpop <- semi_join(wpop_full, iso_codes, by = c("code" = "iso3")) 

wpop
```


# Exercise 5
Show the countries/areas which have the same ISO country code in both wpop and iso_codes but different (spellings of) country names.

```{r}
join_data <- inner_join(wpop, iso_codes, by = c("code" = "iso3"))

different_spelling <- filter(join_data, country != name)

result <- different_spelling |> 
  select(name, code, country)

result

```


# Exercise 6
Use the package rvest to read in the list of countries with corresponding continent codes from the main table at https://en.wikipedia.org/wiki/List_of_sovereign_states_and_dependent_territories_by_continent_(data_file) and select/deselect and rename columns so you end up with a tibble (tbl) named continents with 253 rows and 2 columns with names as shown in the output below.

Important hint: you need convert = FALSE in html_table() to avoid the text string "NA" (North America) to be interpreted as missing data (Not Available).

## Web scraping data from Wikipedia
```{r}
url <- "https://en.wikipedia.org/wiki/List_of_sovereign_states_and_dependent_territories_by_continent_(data_file)"

webpage <- read_html(url)

tables <- webpage |> 
  html_nodes("table") |> # Specify the CSS selector for the table.
  html_table(convert = FALSE)

print(tables)

raw_continents <- tables[[3]]

raw_continents
```

## remove and rename columns
```{r}
colnames(raw_continents)

raw_continents <- raw_continents |>
  rename(
    continent = `CC`,
    iso3 = `a-3`
  )

colnames(raw_continents) #check rename was done

continents <- raw_continents |>
  select(continent, iso3)
```
## Result
```{r}
continents
```


# Exercise 7

# Exercise 8

# Exercise 9

# Exercise 10

# Exercise 11

# Exercise 12

# Exercise 13

# Exercise 14

# Exercise 15

# Exercise 16

# Exercise 17

# Exercise 18

# Exercise 19

# Exercise 20

# Exercise 21

# Exercise 22

# Exercise 23

# Exercise 24
